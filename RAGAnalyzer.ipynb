{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0a7e3e",
   "metadata": {},
   "source": [
    "#  Build a application of RAG test framework.\n",
    "\n",
    "**Description** :\n",
    "\n",
    "1. use vllm as llm service, consider the service is up in docker, and can be accessed by API,\n",
    "\n",
    "2. use llamaindex as RAG framework, \n",
    "\n",
    "3. more then 2000 arxiv paper PDF data is parsed and save in markdown and json\n",
    "\n",
    "4. write a jupyter notebook to run a RAG test framework. Explain the decision it made , for example why use certain chucking method\n",
    "\n",
    "**Task**:\n",
    "\n",
    "1. use a complex method to get relevant paper, \n",
    "\n",
    "    1.1 It requires vectorizing the parsed files with reasonable chucking method.\n",
    "\n",
    "    1.2 It need to filter the paper which has little relation with the RAG method in large language model.\n",
    "\n",
    "2. build a simple UI using \n",
    "\n",
    "**Test question**:\n",
    "\n",
    "1. what is normal ways to optimizaed RAG system\n",
    "\n",
    "2. what is the lastest RAG ideas that might be use to improve our RAG system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import gradio as gr\n",
    "\n",
    "# Set up vLLM API endpoint (OpenAI-compatible)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"  # vLLM does not require a real key\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:8889/v1\"  # Change if your vLLM endpoint differs\n",
    "\n",
    "\n",
    "# Define relevant keywords for filtering\n",
    "RAG_KEYWORDS = [\n",
    "    \"retrieval-augmented\", \"RAG\", \"retrieval\", \"large language model\", \"LLM\", \"knowledge\", \"augmentation\",\n",
    "    \"open-domain\", \"question answering\", \"document retrieval\", \"vector search\", \"semantic search\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4faae7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05e8841d",
   "metadata": {},
   "source": [
    "## Filter the data：\n",
    "\n",
    "using keyword matching is not a good idea, use llm as a reader to catagorize the summary\n",
    "\n",
    "for example, within all RAG related paper, some paper introduce novel method to improve the RAG perfomance, some paper represent the usage of RAG in certain field, some paper happen to contain the keyword but has nothing to do with the technology.\n",
    "\n",
    "now build a filter based on llm, the llm model is packed with vllm and access through http://localhost:8889/v1 in openai format.\n",
    "\n",
    "data input:\n",
    "all PDF papers are parsed and save into the D:\\DataAnalysis\\arxiv\\output in seperate files. inside each file, a markdown file stores the parsed result, the summary is stored under the tag \"# Abstract\" \n",
    "\n",
    "task:\n",
    "1 maintain a list of tags. these tags describe the catagories of the paper. For the start, the abover described catagoty can be used as first batch of tags. Tag1: introduce novel method to improve the RAG perfomance. Tag2: usage of RAG in certain field. Tag3: has nothing to do with the technology. More tags can be generated as the llm read more paper summaries. \n",
    "\n",
    "2 read all paper summary, get the llm judgement, save its tag into a file which contains the file name and the tag\n",
    "\n",
    "3 mind that this work is related to later process to get access to the relevent paper\n",
    "\n",
    "requirement:\n",
    "1 using python and can be executed in jupyter notebook\n",
    "\n",
    "2 asynchronous send query to vllm to reduce the time consumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3851623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\1007.1378v3\\1007.1378v3.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\1007.1378v3\\1007.1378v3.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2308.10462v3\\2308.10462v3.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2308.00479v1\\2308.00479v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2308.00479v1\\2308.00479v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2312.17264v1\\2312.17264v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2311.09114v2\\2311.09114v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2311.09114v2\\2311.09114v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2401.15378v5\\2401.15378v5.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2401.17043v3\\2401.17043v3.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2401.17645v1\\2401.17645v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2402.00247v2\\2402.00247v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2401.00280v3\\2401.00280v3.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2401.00280v3\\2401.00280v3.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2402.05128v3\\2402.05128v3.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2402.11891v1\\2402.11891v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2402.01741v2\\2402.01741v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2402.01741v2\\2402.01741v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2402.19421v1\\2402.19421v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2402.13625v2\\2402.13625v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2402.13625v2\\2402.13625v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2403.14374v1\\2403.14374v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2403.14421v3\\2403.14421v3.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2403.09226v2\\2403.09226v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2403.09226v2\\2403.09226v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2404.06082v1\\2404.06082v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2404.10981v2\\2404.10981v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2404.02319v2\\2404.02319v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2404.02319v2\\2404.02319v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2404.12560v1\\2404.12560v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2404.12560v1\\2404.12560v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2405.13002v1\\2405.13002v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2405.03085v1\\2405.03085v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2405.03085v1\\2405.03085v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2405.15436v1\\2405.15436v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2405.15436v1\\2405.15436v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2406.04369v1\\2406.04369v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.00456v2\\2406.00456v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.00456v2\\2406.00456v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2406.07973v2\\2406.07973v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.07973v2\\2406.07973v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.07973v2\\2406.07973v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2406.18114v3\\2406.18114v3.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.13663v4\\2406.13663v4.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.13663v4\\2406.13663v4.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.19234v2\\2406.19234v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2406.19234v2\\2406.19234v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2407.05502v3\\2407.05502v3.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2407.05502v3\\2407.05502v3.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2407.14116v1\\2407.14116v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2407.14246v3\\2407.14246v3.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2407.19794v2\\2407.19794v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2407.12843v5\\2407.12843v5.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2407.12843v5\\2407.12843v5.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2408.00727v3\\2408.00727v3.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2408.01462v1\\2408.01462v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2408.04125v2\\2408.04125v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2407.21059v1\\2407.21059v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2407.21059v1\\2407.21059v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2408.05933v1\\2408.05933v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2408.08921v2\\2408.08921v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2408.08925v1\\2408.08925v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2408.05242v1\\2408.05242v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2408.05242v1\\2408.05242v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2409.02864v3\\2409.02864v3.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2408.13273v1\\2408.13273v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2408.13273v1\\2408.13273v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2409.07110v2\\2409.07110v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2409.12682v1\\2409.12682v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2409.06062v1\\2409.06062v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2409.06062v1\\2409.06062v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2409.14206v1\\2409.14206v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2409.15228v3\\2409.15228v3.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2409.13695v1\\2409.13695v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2409.13695v1\\2409.13695v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.03049v1\\2410.03049v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2409.18986v2\\2409.18986v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2409.18986v2\\2409.18986v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.04343v2\\2410.04343v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.05983v1\\2410.05983v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.07176v1\\2410.07176v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.08801v1\\2410.08801v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.03754v1\\2410.03754v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.03754v1\\2410.03754v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.09090v1\\2410.09090v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.09090v1\\2410.09090v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.13326v1\\2410.13326v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.13542v1\\2410.13542v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.14881v2\\2410.14881v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.14931v1\\2410.14931v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.15016v1\\2410.15016v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.12475v2\\2410.12475v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.12475v2\\2410.12475v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.16229v2\\2410.16229v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.18792v2\\2410.18792v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2410.19135v1\\2410.19135v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.15284v1\\2410.15284v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.15284v1\\2410.15284v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.20142v2\\2410.20142v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2410.20142v2\\2410.20142v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2411.07021v2\\2411.07021v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2411.01022v1\\2411.01022v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2411.01022v1\\2411.01022v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2411.08438v1\\2411.08438v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2411.11033v1\\2411.11033v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2411.13560v1\\2411.13560v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2411.07404v2\\2411.07404v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2411.07404v2\\2411.07404v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2412.00608v3\\2412.00608v3.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2411.13773v1\\2411.13773v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2411.13773v1\\2411.13773v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2412.04185v1\\2412.04185v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.01572v4\\2412.01572v4.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.01572v4\\2412.01572v4.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2412.13988v1\\2412.13988v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.07687v2\\2412.07687v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.07687v2\\2412.07687v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2412.18069v2\\2412.18069v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.14751v1\\2412.14751v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.14751v1\\2412.14751v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.18295v2\\2412.18295v2.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2412.18295v2\\2412.18295v2.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2501.04006v1\\2501.04006v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.02844v3\\2501.02844v3.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.02844v3\\2501.02844v3.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2501.10893v1\\2501.10893v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.07861v1\\2501.07861v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.07861v1\\2501.07861v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2501.16191v1\\2501.16191v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.13954v1\\2501.13954v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.13954v1\\2501.13954v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.18539v1\\2501.18539v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2501.18539v1\\2501.18539v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.06148v1\\2502.06148v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.06148v1\\2502.06148v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.10976v1\\2502.10976v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.10976v1\\2502.10976v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2502.15718v1\\2502.15718v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.13847v1\\2502.13847v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.13847v1\\2502.13847v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.15990v1\\2502.15990v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.15990v1\\2502.15990v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2502.20812v1\\2502.20812v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.19629v1\\2502.19629v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2502.19629v1\\2502.19629v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.02692v1\\2503.02692v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.02692v1\\2503.02692v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2503.10677v2\\2503.10677v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2503.10707v2\\2503.10707v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.08398v1\\2503.08398v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.08398v1\\2503.08398v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2503.17553v1\\2503.17553v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.13654v1\\2503.13654v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.13654v1\\2503.13654v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2503.19573v1\\2503.19573v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.18923v1\\2503.18923v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2503.18923v1\\2503.18923v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.03931v2\\2504.03931v2.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.00409v1\\2504.00409v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.00409v1\\2504.00409v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.05309v1\\2504.05309v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.07724v1\\2504.07724v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.04988v1\\2504.04988v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.04988v1\\2504.04988v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.08747v1\\2504.08747v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.08748v1\\2504.08748v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.09207v1\\2504.09207v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.10147v1\\2504.10147v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.10369v1\\2504.10369v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.10499v1\\2504.10499v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.08386v1\\2504.08386v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.08386v1\\2504.08386v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.12309v2\\2504.12309v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.12845v1\\2504.12845v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.12931v1\\2504.12931v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.10893v1\\2504.10893v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.10893v1\\2504.10893v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.15610v2\\2504.15610v2.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.16883v1\\2504.16883v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.18369v1\\2504.18369v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2504.19413v1\\2504.19413v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.14917v1\\2504.14917v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.14917v1\\2504.14917v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2505.00105v1\\2505.00105v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2505.03075v1\\2505.03075v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2505.03807v1\\2505.03807v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.20653v1\\2504.20653v1.md ... (40 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2504.20653v1\\2504.20653v1.md ... (40 files)\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2505.04651v1\\2505.04651v1.md\n",
      "[SKIP] No abstract in: D:\\DataAnalysis\\arxiv\\output\\2505.04680v1\\2505.04680v1.md\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2505.04068v1\\2505.04068v1.md ... (15 files)\n",
      "Processed batch: D:\\DataAnalysis\\arxiv\\output\\2505.04068v1\\2505.04068v1.md ... (15 files)\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import nest_asyncio\n",
    "import pprint\n",
    "\n",
    "nest_asyncio.apply()\n",
    "# Define initial tags/categories\n",
    "TAGS = [\n",
    "    \"introduce novel method to improve the RAG performance\",\n",
    "    \"usage of RAG in certain field\",\n",
    "    \"has nothing to do with the retrieval augmented generation in large language model application\",\n",
    "    \"retrieval augmented generation only mention but not be discussed in detail\",\n",
    "    \"cannot be catagorized into any mentioned tags, others\"\n",
    "]\n",
    "\n",
    "new_tags = []\n",
    "semaphore = asyncio.Semaphore(5)\n",
    "output_filter_dir = r\"D:\\DataAnalysis\\arxiv\\output_filter\"\n",
    "\n",
    "# Helper: extract abstract from markdown\n",
    "#def extract_abstract(md_text):\n",
    "#    match = re.search(r\"# Abstract\\s*(.+?)(?:\\n#|\\Z)\", md_text, re.DOTALL)\n",
    "#    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "def extract_abstract(md_text):\n",
    "    # 支持 \"# Abstract\", \"Abstract.\", \"Abstract:\", \"## Abstract\" 等多种写法\n",
    "    match = re.search(\n",
    "        r\"(?:^|\\n)\\s{0,3}(?:#*\\s*)?Abstract[\\.:]?\\s*(.+?)(?:\\n#|\\n[A-Z][^a-z]|$)\",\n",
    "        md_text, re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "# Async function to call vLLM (OpenAI API format)\n",
    "async def classify_abstract(session, abstract, tags):\n",
    "    async with semaphore:\n",
    "        prompt = (\n",
    "            f\"Given the following paper abstract, classify it into one of these categories:\\n\"\n",
    "            f\"{json.dumps(tags)}\\n\"\n",
    "            f\"Abstract:\\n{abstract}\\n\"\n",
    "            f\"Respond with the most suitable category from the list. Do not output any other word other than the name of the type. \\n /no_think\"\n",
    "        )\n",
    "        payload = {\n",
    "            \"model\": \"/models/Qwen3-8B\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 50,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "        async with session.post(\n",
    "            \"http://localhost:8889/v1/chat/completions\",\n",
    "            json=payload,\n",
    "            timeout=60\n",
    "        ) as resp:\n",
    "            result = await resp.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "# 批处理\n",
    "def batch_iter(md_files, batch_size):\n",
    "    \"\"\"Yield successive batch_size-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(md_files), batch_size):\n",
    "        yield md_files[i:i + batch_size]\n",
    "\n",
    "async def filter_and_tag_papers_in_batches(md_files, tags, batch_size=20):\n",
    "    results = []\n",
    "    with open(\"paper_tags.jsonl\", \"a\", encoding=\"utf-8\") as f1:  # 以追加模式打开\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            for batch in batch_iter(md_files, batch_size):\n",
    "                tasks = []\n",
    "                for md_file in batch:\n",
    "                    with open(md_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                        md_text = f.read()\n",
    "                    abstract = extract_abstract(md_text)\n",
    "                    if not abstract:\n",
    "                        print(f\"[SKIP] No abstract in: {md_file}\")\n",
    "                        continue\n",
    "                    tasks.append(classify_abstract(session, abstract, tags))\n",
    "                # gather this batch\n",
    "                tag_results = await asyncio.gather(*tasks)\n",
    "                print(f\"Processed batch: {batch[0]} ... ({len(batch)} files)\")\n",
    "                for md_file, tag in zip(batch, tag_results):\n",
    "                    # 去除 <think> 标签\n",
    "                    if isinstance(tag, str):\n",
    "                        tag = tag.replace(\"<think>\\n\\n</think>\\n\\n\", \"\").strip()\n",
    "                    result = {\"file\": md_file, \"tag\": tag}\n",
    "                    results.append(result)\n",
    "                    # 如果是无关论文，立即移动文件夹\n",
    "                    if tag == \"has nothing to do with the retrieval-augmented generation in large language model application\":\n",
    "                        parent_dir = os.path.dirname(md_file)\n",
    "                        dest_dir = os.path.join(output_filter_dir, os.path.basename(parent_dir))\n",
    "                        if not os.path.exists(dest_dir):\n",
    "                            print(f\"Moving {parent_dir} -> {dest_dir}\")\n",
    "                            shutil.move(parent_dir, dest_dir)\n",
    "                            print(f\"Moving: {batch[0]} ... ({len(batch)} files)\")\n",
    "                    f1.write(json.dumps(result, ensure_ascii=False) + \"\\n\")  # 追加写入一行\n",
    "                    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Main async filter function 非批处理（会有奇怪错误）\n",
    "async def filter_and_tag_papers(md_files, tags):\n",
    "    results = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for md_file in md_files:\n",
    "            with open(md_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                md_text = f.read()\n",
    "            abstract = extract_abstract(md_text)\n",
    "            if not abstract:\n",
    "                print(f\"[SKIP] No abstract in: {md_file}\")\n",
    "                continue\n",
    "            tasks.append(classify_abstract(session, abstract, tags))\n",
    "        tag_results = await asyncio.gather(*tasks)\n",
    "        for md_file, tag in zip(md_files, tag_results):\n",
    "            results.append({\"file\": md_file, \"tag\": tag})\n",
    "    return results\n",
    "\n",
    "# Gather all markdown files\n",
    "md_files = glob.glob(r\"D:\\DataAnalysis\\arxiv\\output\\*\\*.md\")\n",
    "\n",
    "# Run the async filter and save results\n",
    "#tagged_results = await filter_and_tag_papers(md_files, TAGS)\n",
    "\n",
    "tagged_results = await filter_and_tag_papers_in_batches(md_files, TAGS, 40)\n",
    "\n",
    "\n",
    "\n",
    "# Save to file for later use\n",
    "#with open(\"paper_tags.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#    json.dump(tagged_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "#for result in tagged_results:\n",
    "#    print(f\"Tagged {len(tagged_results)} papers. Example:\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b741a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DataAnalysis\\\\arxiv\\\\output_filter\\\\a'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir=r\"D:\\DataAnalysis\\arxiv\\output\\a\\a.md\"\n",
    "\n",
    "dest_dir = os.path.join(output_filter_dir, os.path.basename(os.path.dirname(dir)))\n",
    "dest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(md_file)\n",
    "dest_dir = os.path.join(output_filter_dir, os.path.basename(parent_dir))\n",
    "if not os.path.exists(dest_dir):\n",
    "    print(f\"Moving {parent_dir} -> {dest_dir}\")\n",
    "    shutil.move(parent_dir, dest_dir)\n",
    "    print(f\"Moving: {batch[0]} ... ({len(batch)} files)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9acc35",
   "metadata": {},
   "source": [
    "## 2. Chunking and Vectorization Strategy\n",
    "\n",
    "local embedding model：Qwen/Qwen3-Embedding-8B\n",
    "\n",
    "data input:\n",
    "all PDF papers are parsed and save into the D:\\DataAnalysis\\arxiv\\output in seperate files. inside each file, a markdown file stores the parsed result, the summary is stored under the tag \"# Abstract\" \n",
    "\n",
    "task:\n",
    "1 maintain a list of tags. these tags describe the catagories of the paper. For the start, the abover described catagoty can be used as first batch of tags. Tag1: introduce novel method to improve the RAG perfomance. Tag2: usage of RAG in certain field. Tag3: has nothing to do with the technology. More tags can be generated as the llm read more paper summaries. \n",
    "\n",
    "2 read all paper summary, get the llm judgement, save its tag into a file which contains the file name and the tag\n",
    "\n",
    "3 mind that this work is related to later process to get access to the relevent paper\n",
    "\n",
    "requirement:\n",
    "1 using python and can be executed in jupyter notebook\n",
    "\n",
    "2 asynchronous send query to vllm to reduce the time consumed\n",
    "\n",
    "functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load model directly\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-Embedding-8B\")\n",
    "model = AutoModel.from_pretrained(\"Qwen/Qwen3-Embedding-8B\")\n",
    "\n",
    "# Example: encode a batch of texts and get embeddings\n",
    "def get_hf_embeddings(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        # Use the last hidden state as embeddings (mean pooling)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Example usage:\n",
    "# embeddings = get_hf_embeddings([\"Retrieval-augmented generation\", \"Large language models\"])\n",
    "\n",
    "\n",
    "# Build the vector index with chunking\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")  # Use vLLM's embedding endpoint if available\n",
    "\n",
    "# Create the index (this may take a while for 2000+ papers)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    relevant_docs,\n",
    "    embed_model=embed_model,\n",
    "    vector_store=FaissVectorStore()\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)  # Use vLLM's API\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similarity_top_k=5,  # Retrieve top 5 relevant chunks\n",
    "    response_mode=\"compact\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41222b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Simple UI for RAG Testing\n",
    "def rag_query(question):\n",
    "    response = query_engine.query(question)\n",
    "    return str(response)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=rag_query,\n",
    "    inputs=gr.Textbox(label=\"Enter your RAG question\"),\n",
    "    outputs=gr.Textbox(label=\"RAG Answer\"),\n",
    "    title=\"RAG Test Framework (vLLM + LlamaIndex)\",\n",
    "    description=\"Ask questions about RAG or LLMs. The system retrieves from filtered arXiv papers and generates answers using vLLM.\"\n",
    ")\n",
    "\n",
    "# Uncomment to launch the UI\n",
    "# demo.launch(share=True)\n",
    "## 5. Test Questions\n",
    "\n",
    "test_questions = [\n",
    "    \"What is normal ways to optimizaed RAG system?\",\n",
    "    \"What is the lastest RAG ideas that might be use to improve our RAG system?\"\n",
    "]\n",
    "for q in test_questions:\n",
    "    print(f\"Q: {q}\")\n",
    "    print(\"A:\", rag_query(q))\n",
    "    print(\"=\"*60)\n",
    "\n",
    "## 6. Summary of Decisions\n",
    "\n",
    "#- **Chunking:** Used heading/paragraph-based chunking to preserve academic structure and semantic boundaries.\n",
    "#- **Filtering:** Only included papers with strong relevance to RAG/LLM, improving retrieval quality and speed.\n",
    "#- **Vectorization:** Used OpenAI-compatible embeddings via vLLM for local, fast, and cost-effective embedding.\n",
    "#- **UI:** Provided a simple Gradio interface for interactive testing.\n",
    "\n",
    "#This framework can be extended with more advanced chunking, reranking, or hybrid retrieval methods as new RAG research emerges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb436850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55256269ac5b453787bf2e48d5544fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7493017911911011, 0.07506479322910309], [0.08795973658561707, 0.6318399906158447]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "# Each query must come with a one-sentence instruction that describes the task\n",
    "task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "\n",
    "queries = [\n",
    "    get_detailed_instruct(task, 'What is the capital of China?'),\n",
    "    get_detailed_instruct(task, 'Explain gravity')\n",
    "]\n",
    "# No need to add instruction for retrieval documents\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\"\n",
    "]\n",
    "input_texts = queries + documents\n",
    "local_model_path = \"D:/vllm_yml/models/Qwen3-Embedding-8B\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, padding_side='left')\n",
    "model = AutoModel.from_pretrained(local_model_path)\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving.\n",
    "# model = AutoModel.from_pretrained('Qwen/Qwen3-Embedding-8B', attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16).cuda()\n",
    "\n",
    "max_length = 8192\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(\n",
    "    input_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "batch_dict.to(model.device)\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "# normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T)\n",
    "print(scores.tolist())\n",
    "# [[0.7493016123771667, 0.0750647559762001], [0.08795969933271408, 0.6318399906158447]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e69862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3Model(\n",
      "  (embed_tokens): Embedding(151665, 4096)\n",
      "  (layers): ModuleList(\n",
      "    (0-35): 36 x Qwen3DecoderLayer(\n",
      "      (self_attn): Qwen3Attention(\n",
      "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "      )\n",
      "      (mlp): Qwen3MLP(\n",
      "        (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
      "      (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
      "  (rotary_emb): Qwen3RotaryEmbedding()\n",
      ")\n",
      "Qwen2TokenizerFast(name_or_path='D:/vllm_yml/models/Qwen3-Embedding-8B', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "}\n",
      ")\n",
      "BaseModelOutputWithPast(last_hidden_state=tensor([[[-1.2399,  0.9224, -0.4252,  ...,  1.3754,  1.3721,  1.3900],\n",
      "         [-0.3362,  1.6757,  0.8191,  ...,  0.0199, -1.0900,  2.5982],\n",
      "         [ 3.3527,  1.9358, -1.9853,  ..., -2.7769, -0.7726,  4.3275]]]), past_key_values=<transformers.cache_utils.DynamicCache object at 0x000001A470960460>, hidden_states=None, attentions=None)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#  \n",
    "print(model)\n",
    "print(tokenizer)\n",
    "\n",
    "# simple inut \n",
    "test_text = \"Hello world\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs)\n",
    "    print(torch.isnan(outputs.last_hidden_state).any())  # check if nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34d7587",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# 确保推理模式\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello world\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(test_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()  # \n",
    "\n",
    "test_text = \"Hello world\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "print(inputs)  #  \n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs)\n",
    "    print(torch.isnan(outputs.last_hidden_state).any())  # check if nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3800368d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  9707,   1879, 151643]]),\n",
       " 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c503bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c793d801214334a2c608b7e4fd5248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7493017911911011, 0.07506479322910309], [0.08795973658561707, 0.6318399906158447]]\n"
     ]
    }
   ],
   "source": [
    "# Requires transformers>=4.51.0\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "# Each query must come with a one-sentence instruction that describes the task\n",
    "task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "\n",
    "queries = [\n",
    "    get_detailed_instruct(task, 'What is the capital of China?'),\n",
    "    get_detailed_instruct(task, 'Explain gravity')\n",
    "]\n",
    "# No need to add instruction for retrieval documents\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\"\n",
    "]\n",
    "input_texts = queries + documents\n",
    "local_model_path = \"D:/vllm_yml/models/Qwen3-Embedding-8B\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, padding_side='left')\n",
    "model = AutoModel.from_pretrained(local_model_path)\n",
    "\n",
    "\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving.\n",
    "# model = AutoModel.from_pretrained('Qwen/Qwen3-Embedding-8B', attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16).cuda()\n",
    "\n",
    "max_length = 8192\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(\n",
    "    input_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "batch_dict.to(model.device)\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "# normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T)\n",
    "print(scores.tolist())\n",
    "# [[0.7493016123771667, 0.0750647559762001], [0.08795969933271408, 0.6318399906158447]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734b662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41500301f8244129b95dbc92f5a61b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7526, 0.0758],\n",
      "        [0.0849, 0.6434]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "local_model_path = \"D:/vllm_yml/models/Qwen3-Embedding-8B\"\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(local_model_path)\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving,\n",
    "# together with setting `padding_side` to \"left\":\n",
    "# model = SentenceTransformer(\n",
    "#     \"Qwen/Qwen3-Embedding-8B\",\n",
    "#     model_kwargs={\"attn_implementation\": \"flash_attention_2\", \"device_map\": \"auto\"},\n",
    "#     tokenizer_kwargs={\"padding_side\": \"left\"},\n",
    "# )\n",
    "\n",
    "# The queries and documents to embed\n",
    "task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "queries = [\n",
    "    get_detailed_instruct(task, 'What is the capital of China?'),\n",
    "    get_detailed_instruct(task, 'Explain gravity')\n",
    "]\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Encode the queries and documents. Note that queries benefit from using a prompt\n",
    "# Here we use the prompt called \"query\" stored under `model.prompts`, but you can\n",
    "# also pass your own prompt via the `prompt` argument\n",
    "query_embeddings = model.encode(queries, prompt_name=\"query\")\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "# Compute the (cosine) similarity between the query and document embeddings\n",
    "similarity = model.similarity(query_embeddings, document_embeddings)\n",
    "print(similarity)\n",
    "# tensor([[0.7493, 0.0751],\n",
    "#         [0.0880, 0.6318]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbdd7259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01385963,  0.05234203, -0.00317804, ..., -0.00441788,\n",
       "         0.00941126,  0.01125732],\n",
       "       [ 0.0389513 ,  0.01941089, -0.01117104, ..., -0.00961749,\n",
       "         0.00640514, -0.00067327]], shape=(2, 4096), dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
