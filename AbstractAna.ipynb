{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6129feb",
   "metadata": {},
   "source": [
    "# output the codes for the following task, need to setup a good framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09b9cc",
   "metadata": {},
   "source": [
    "**Aim**: classification of articles based on abstract\n",
    "\n",
    "**structure**: use LLM to automate create tags based on the \n",
    "\n",
    "     1 Read the abstract and catagory from db,  \n",
    "\n",
    "     2 catagory is first level tags, too many articles have the same tags, create a loop for all catagory\n",
    "\n",
    "        2.1 in the loop, for each catagory, label all of them with multiple tags using an openAI LLM tool using vllm engine,\n",
    "        2.2 the tags could be 10~20 , capture the essence of the abstract,\n",
    "        2.3 add multiple columes in the database, put all tags in one colume \n",
    "        \n",
    "     3 Now get a new papar abstract, analyze its key word and serch in the databese to find the most relevent ones, apply a threhold to get rid of irrelevent papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13411e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading abstracts from database: could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (::1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (127.0.0.1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DB connection & sample read (PostgreSQL)\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "HOST = 'localhost'  # 数据库主机\n",
    "PORT = '5432'  # PostgreSQL 默认端口\n",
    "USER = 'postgres'  # 用于创建数据库的管理员用户名\n",
    "PASSWORD = '123456'  # 管理员密码\n",
    "DB_NAME = 'arxiv_db'  # 要创建的数据库名称\n",
    "DB_USER = 'postgres'  # 新用户\n",
    "DB_USER_PASSWORD = '123456'  # 新用户密码\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_USER_PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # 读取摘要和一级类别标签\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT id, abstract, categories FROM arxiv_papers\n",
    "        WHERE abstract IS NOT NULL AND categories IS NOT NULL AND llm_tags IS NULL;\n",
    "    \"\"\")\n",
    "    papers = cur.fetchall()\n",
    "\n",
    "    # 示例：打印前5条记录\n",
    "    for paper in papers[:1]:\n",
    "        print(f\"ID: {paper[0]}\\nCategory: {paper[2]}\\nAbstract: {paper[1][:200]}...\\n{'-'*40}\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading abstracts from database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025bea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "def remove_think_tag(text):\n",
    "    # Remove <think>...</think> and any leading/trailing whitespace/newlines\n",
    "    return re.sub(r\"<think>.*</think>\\s*\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "\n",
    "async def async_generate_tags_with_llm(abstracts_batch, n_tags=20, session=None):\n",
    "    \"\"\"\n",
    "    Use vllm engine (OpenAI-compatible API at localhost:8889) to generate tags for the given abstract.\n",
    "    Returns a list of tags.\n",
    "    \"\"\"\n",
    "    # abstracts_batch = 【id, abstract, catagory】\n",
    "    system_prompt = (\n",
    "        f\"Read the following scientific abstract and generate less than {n_tags} concise, relevant tags \"\n",
    "        f\"that capture its main topics and concepts. Return the tags as a comma-separated list.\\n\\n \"\n",
    "        f\"Abstract:{abstracts_batch[1]}  Tags: \\n\\n /no_think\"\n",
    "    )\n",
    "    messages= [\n",
    "    #     {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": system_prompt }\n",
    "    ]\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"/models/Qwen3-8B\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 1280,\n",
    "        \"temperature\": 0.3,\n",
    "    }\n",
    "    try:\n",
    "        async with session.post(\n",
    "            \"http://localhost:8889/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        ) as response:\n",
    "            response.raise_for_status()\n",
    "            result = await response.json()\n",
    "            tag_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            tag_text = remove_think_tag(tag_text)\n",
    "            tags = [tag.strip() for tag in tag_text.split(\",\") if tag.strip()]\n",
    "            return tags\n",
    "    \n",
    " \n",
    "    except Exception as e:\n",
    "        print(f\"LLM tag generation failed: {e}\")\n",
    "        return []\n",
    "    \n",
    "\n",
    "async def batch_generate_tags_with_llm(abstracts_batch, n_tags=20):\n",
    "    \"\"\"\n",
    "    批量异步处理摘要，返回 [(paper_id, category, tags), ...]\n",
    "    \"\"\"\n",
    "    semaphore = asyncio.Semaphore(50)\n",
    "\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [\n",
    "            async_generate_tags_with_llm(abstract, n_tags, session)\n",
    "            for abstract in abstracts_batch\n",
    "        ]\n",
    "        tags_list = await asyncio.gather(*tasks)\n",
    "    # 组装结果\n",
    "    return [\n",
    "        (paper_id, category, tags)\n",
    "        for (paper_id, _, category), tags in zip(abstracts_batch, tags_list)\n",
    "    ]\n",
    "\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def store_tags_in_db(tagged_papers: List[Tuple[str, str, List[str]]]) -> None:\n",
    "    \"\"\"\n",
    "    Store the generated tags into the original arxiv_papers table.\n",
    "    Adds a new column 'llm_tags' if it does not exist, then updates each row.\n",
    "\n",
    "    Args:\n",
    "        tagged_papers: List of tuples (paper_id, category, tags)\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_USER_PASSWORD,\n",
    "            host=HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Add the 'llm_tags' column if it doesn't exist\n",
    "        cur.execute(\"\"\"\n",
    "            DO $$\n",
    "            BEGIN\n",
    "                IF NOT EXISTS (\n",
    "                    SELECT 1 FROM information_schema.columns \n",
    "                    WHERE table_name='arxiv_papers' AND column_name='llm_tags'\n",
    "                ) THEN\n",
    "                    ALTER TABLE arxiv_papers ADD COLUMN llm_tags TEXT;\n",
    "                END IF;\n",
    "            END$$;\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Update each paper with its tags\n",
    "        for paper_id, category, tags in tagged_papers:\n",
    "            tags_str = \", \".join(tags)\n",
    "            #print(paper_id)\n",
    "\n",
    "            cur.execute(\n",
    "                \"UPDATE arxiv_papers SET llm_tags = %s WHERE id = %s;\",\n",
    "                (tags_str, paper_id)\n",
    "            )\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        print(\"Tags successfully stored in the database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error storing tags in database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75fc646",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: Connection refused\n\tIs the server running on host \"localhost\" (::1) and accepting\n\tTCP/IP connections on port 5432?\ncould not connect to server: Connection refused\n\tIs the server running on host \"localhost\" (127.0.0.1) and accepting\n\tTCP/IP connections on port 5432?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m offset\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m1000000\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     papers_batch \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_papers_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m papers_batch:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mfetch_papers_batch\u001b[0;34m(offset, limit)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_papers_batch\u001b[39m(offset, limit):\n\u001b[0;32m---> 10\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDB_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDB_USER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDB_USER_PASSWORD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHOST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPORT\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     cur \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m     18\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m        SELECT id, abstract, categories FROM arxiv_papers\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m        WHERE abstract IS NOT NULL AND categories IS NOT NULL AND llm_tags IS NULL\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m        ORDER BY id\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m        OFFSET \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m LIMIT \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m;\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, (offset, limit))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: Connection refused\n\tIs the server running on host \"localhost\" (::1) and accepting\n\tTCP/IP connections on port 5432?\ncould not connect to server: Connection refused\n\tIs the server running on host \"localhost\" (127.0.0.1) and accepting\n\tTCP/IP connections on port 5432?\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "def fetch_papers_batch(offset, limit):\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_USER_PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT id, abstract, categories FROM arxiv_papers\n",
    "        WHERE abstract IS NOT NULL AND categories IS NOT NULL AND llm_tags IS NULL\n",
    "        ORDER BY id\n",
    "        OFFSET %s LIMIT %s;\n",
    "    \"\"\", (offset, limit))\n",
    "    batch = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return batch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "offset = 0\n",
    "while offset<1000000:\n",
    "    papers_batch = fetch_papers_batch(offset, BATCH_SIZE)\n",
    "    if not papers_batch:\n",
    "        break\n",
    "    tagged_batch = await batch_generate_tags_with_llm(papers_batch, n_tags=20)\n",
    "    store_tags_in_db(tagged_batch)\n",
    "    print(f\"Processed batch offset {offset}\")\n",
    "    offset += BATCH_SIZE\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"✅ Completed in {elapsed:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff82b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching papers with LLM tags: could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (::1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (127.0.0.1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "\n",
      "Error fetching last written llm_tags: could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (::1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (127.0.0.1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "\n",
      "Error counting empty llm_tags: could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (::1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (127.0.0.1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "\n",
      "Error updating empty llm_tags to NULL: could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (::1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "could not connect to server: Connection refused\n",
      "\tIs the server running on host \"localhost\" (127.0.0.1) and accepting\n",
      "\tTCP/IP connections on port 5432?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "HOST = 'localhost'  # 数据库主机\n",
    "PORT = '5432'  # PostgreSQL 默认端口\n",
    "USER = 'postgres'  # 用于创建数据库的管理员用户名\n",
    "PASSWORD = '123456'  # 管理员密码\n",
    "DB_NAME = 'arxiv_db'  # 要创建的数据库名称\n",
    "DB_USER = 'postgres'  # 新用户\n",
    "DB_USER_PASSWORD = '123456'  # 新用户密码\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_USER_PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT id, categories, llm_tags\n",
    "        FROM arxiv_papers\n",
    "        WHERE llm_tags IS NOT NULL;\n",
    "    \"\"\")\n",
    "    rows = cur.fetchall()\n",
    "    print(f\"rows 共返回 {len(rows)} 条\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching papers with LLM tags: {e}\")\n",
    "\n",
    "# 获取最后写入数据库的llm_tags记录（按更新时间排序，假设有updated_at或类似时间戳字段）\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_USER_PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    # 如果表中有updated_at或类似字段，按其排序\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT id, categories, llm_tags\n",
    "        FROM arxiv_papers\n",
    "        WHERE llm_tags IS NOT NULL AND TRIM(llm_tags) <> ''\n",
    "        ORDER BY arxiv_papers.update_date DESC\n",
    "        LIMIT 10;\n",
    "    \"\"\")\n",
    "    last_written_rows = cur.fetchall()\n",
    "    print(\"最后写入的10条llm_tags：\")\n",
    "    for row in last_written_rows:\n",
    "        print(f\"ID: {row[0]}, Categories: {row[1]}, LLM Tags: {row[2]}\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching last written llm_tags: {e}\")\n",
    "    \n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_USER_PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM arxiv_papers\n",
    "        WHERE llm_tags IS NOT NULL AND TRIM(llm_tags) = '';\n",
    "    \"\"\")\n",
    "    count = cur.fetchone()[0]\n",
    "    print(f\"llm_tags为非空但内容为空字符串的条数: {count}\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error counting empty llm_tags: {e}\")\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_USER_PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        UPDATE arxiv_papers\n",
    "        SET llm_tags = NULL\n",
    "        WHERE llm_tags IS NOT NULL AND TRIM(llm_tags) = '';\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(f\"已将llm_tags为非空但内容为空字符串的行恢复为NULL\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error updating empty llm_tags to NULL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a3836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error counting empty llm_tags: name 'psycopg2' is not defined\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cc730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99178acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6012544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe95a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82144990",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_abstract=\"\"\" Scientific progress depends on researchers’ ability to synthesize the growing body\n",
    "of literature. Can large language models (LMs) assist scientists in this task? We\n",
    "introduce OPENSCHOLAR, a specialized retrieval-augmented LM that answers\n",
    "scientific queries by identifying relevant passages from 45 million open-access\n",
    "papers and synthesizing citation-backed responses. To evaluate OPENSCHOLAR,\n",
    "we develop SCHOLARQABENCH, the first large-scale multi-domain benchmark\n",
    "for literature search, comprising 2,967 expert-written queries and 208 long-form\n",
    "answers across computer science, physics, neuroscience, and biomedicine. On\n",
    "SCHOLARQABENCH, OPENSCHOLAR-8B outperforms GPT-4o by 5% and PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o\n",
    "hallucinates citations 78–90% of the time, OPENSCHOLAR achieves citation accuracy on par with human experts. OPENSCHOLAR’s datastore, retriever, and\n",
    "self-feedback inference loop also improves off-the-shelf LMs: for instance, OPENSCHOLAR-GPT4o improves GPT-4o’s correctness by 12%. In human evaluations,\n",
    "experts preferred OPENSCHOLAR-8B and OPENSCHOLAR-GPT4o responses over\n",
    "expert-written ones 51% and 70% of the time, respectively, compared to GPT4o’s\n",
    "32%. We open-source all of our code, models, datastore, data and a public demo.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb331ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "import nest_asyncio\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Database connection parameters\n",
    "HOST = 'localhost'\n",
    "PORT = '5432'\n",
    "DB_NAME = 'arxiv_db'\n",
    "DB_USER = 'postgres'\n",
    "DB_USER_PASSWORD = '123456'\n",
    "\n",
    "def remove_think_tag(text):\n",
    "    return re.sub(r\"<think>.*</think>\\s*\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "async def generate_tags_for_abstract(abstract, n_tags=20):\n",
    "    system_prompt = (\n",
    "        f\"Read the following scientific abstract and generate less than {n_tags} concise, relevant tags \"\n",
    "        f\"that capture its main topics and concepts. Return the tags as a comma-separated list.\\n\\n \"\n",
    "        f\"Abstract:{abstract}  Tags: \\n\\n /no_think\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": system_prompt}]\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"/models/Qwen3-8B\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 1280,\n",
    "        \"temperature\": 0.3,\n",
    "    }\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.post(\n",
    "                \"http://localhost:8889/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            ) as response:\n",
    "                response.raise_for_status()\n",
    "                result = await response.json()\n",
    "                tag_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                tag_text = remove_think_tag(tag_text)\n",
    "                tags = [tag.strip() for tag in tag_text.split(\",\") if tag.strip()]\n",
    "                return tags\n",
    "        except Exception as e:\n",
    "            print(f\"LLM tag generation failed: {e}\")\n",
    "            return []\n",
    "\n",
    "def test_single_abstract(abstract, n_tags=20):\n",
    "    tags = asyncio.run(generate_tags_for_abstract(abstract, n_tags))\n",
    "    print(\"Generated Tags:\")\n",
    "    print(tags)\n",
    "    return tags\n",
    "\n",
    "# Example usage:\n",
    "test_abstract = \"\"\" Scientific progress depends on researchers’ ability to synthesize the growing body\n",
    "of literature. Can large language models (LMs) assist scientists in this task? We\n",
    "introduce OPENSCHOLAR, a specialized retrieval-augmented LM that answers\n",
    "scientific queries by identifying relevant passages from 45 million open-access\n",
    "papers and synthesizing citation-backed responses. To evaluate OPENSCHOLAR,\n",
    "we develop SCHOLARQABENCH, the first large-scale multi-domain benchmark\n",
    "for literature search, comprising 2,967 expert-written queries and 208 long-form\n",
    "answers across computer science, physics, neuroscience, and biomedicine. On\n",
    "SCHOLARQABENCH, OPENSCHOLAR-8B outperforms GPT-4o by 5% and PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o\n",
    "hallucinates citations 78–90% of the time, OPENSCHOLAR achieves citation accuracy on par with human experts. OPENSCHOLAR’s datastore, retriever, and\n",
    "self-feedback inference loop also improves off-the-shelf LMs: for instance, OPENSCHOLAR-GPT4o improves GPT-4o’s correctness by 12%. In human evaluations,\n",
    "experts preferred OPENSCHOLAR-8B and OPENSCHOLAR-GPT4o responses over\n",
    "expert-written ones 51% and 70% of the time, respectively, compared to GPT4o’s\n",
    "32%. We open-source all of our code, models, datastore, data and a public demo.\"\"\"\n",
    "\n",
    "# Run the test\n",
    "test_single_abstract(test_abstract, n_tags=20)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed005212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
