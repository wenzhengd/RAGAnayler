{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbb2c91",
   "metadata": {},
   "source": [
    "\n",
    "# MinerU â€” Clean, Structured Version (no server required)\n",
    "\n",
    "This notebook wraps the MinerU / `magic_pdf` pipeline into clear, reusable functions.  \n",
    "It keeps the **same functionality** as the original intent:\n",
    "- Iterate PDFs under `downloads/` (recursively if desired)\n",
    "- Skip already-parsed files via `parsed_list.txt`\n",
    "- Run document analysis (`doc_analyze`) and export:\n",
    "  - Markdown (`.md`), images, and content list (`_content_list.json`)\n",
    "  - Intermediate JSON (`_middle.json`)\n",
    "  - Layout and span visualization PDFs\n",
    "- Robust logging and error handling\n",
    "\n",
    "> **Note:** This version is designed to run **with or without a GPU**. If a GPU is available, it will be used; otherwise the pipeline runs on CPU (slower). You don't need vLLM or a model server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Set, Optional, Dict, Tuple\n",
    "\n",
    "# Optional: tqdm for progress\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    tqdm = lambda x, **k: x  # fallback\n",
    "\n",
    "# MinerU / magic_pdf\n",
    "from magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader\n",
    "from magic_pdf.data.dataset import PymuDocDataset\n",
    "from magic_pdf.model.doc_analyze_by_custom_model import doc_analyze\n",
    "from magic_pdf.config.enums import SupportedPdfParseMethod\n",
    "\n",
    "# If CUDA is available, honor CUDA_VISIBLE_DEVICES if set. Otherwise run on CPU.\n",
    "# You can override with: os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" (or \"\" for CPU)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"(not set)\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb02b74e",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Root directory (by default, current working directory)\n",
    "ROOT = Path(os.getcwd())\n",
    "\n",
    "# Input PDFs directory\n",
    "INPUT_DIR = ROOT / \"downloads\"  # change if needed\n",
    "\n",
    "# Output root (MinerU artifacts)\n",
    "OUT_DIR = ROOT / \"mineru_out\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parsed list file to skip already-processed PDFs\n",
    "PARSED_LIST_FILE = ROOT / \"parsed_list.txt\"\n",
    "\n",
    "# Parsing method: choose a SupportedPdfParseMethod (e.g., PYMU, PDFMINER)\n",
    "PARSE_METHOD = SupportedPdfParseMethod.PYMU  # typically PymuPDF works well\n",
    "\n",
    "# Whether to search INPUT_DIR recursively for PDFs\n",
    "RECURSIVE = True\n",
    "\n",
    "# Max PDFs to process in one run (None = no limit)\n",
    "MAX_PDFS: Optional[int] = None\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"INPUT_DIR:\", INPUT_DIR)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "print(\"PARSE_METHOD:\", PARSE_METHOD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1a5b3",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9db41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_parsed_list(path: Path) -> Set[str]:\n",
    "    if path.exists():\n",
    "        return set(p.strip() for p in path.read_text(encoding=\"utf-8\").splitlines() if p.strip())\n",
    "    else:\n",
    "        path.write_text(\"\", encoding=\"utf-8\")\n",
    "        return set()\n",
    "\n",
    "def save_parsed_list(path: Path, parsed: Set[str]) -> None:\n",
    "    path.write_text(\"\\n\".join(sorted(parsed)), encoding=\"utf-8\")\n",
    "\n",
    "def iter_pdfs(root: Path, recursive: bool = True) -> Iterable[Path]:\n",
    "    if recursive:\n",
    "        yield from root.rglob(\"*.pdf\")\n",
    "    else:\n",
    "        yield from root.glob(\"*.pdf\")\n",
    "\n",
    "def safe_name(pdf_path: Path) -> str:\n",
    "    # Keep arXiv-like prefix + title portion if present, otherwise filename stem\n",
    "    # Example: '1610.00402v2.Dynamic_Polygon_Clouds__Representation_and_Compression_for_VR_AR.pdf'\n",
    "    # -> '1610.00402v2.Dynamic_Polygon_Clouds__Representation_and_Compression_for_VR_AR'\n",
    "    parts = pdf_path.name.split(\".\")\n",
    "    if len(parts) >= 3 and parts[0].isdigit():  # heuristic for arXiv-like names\n",
    "        return \".\".join(parts[:2])\n",
    "    return pdf_path.stem\n",
    "\n",
    "def ensure_dirs(base: Path, name_without_ext: str) -> Tuple[Path, Path, Path]:\n",
    "    \"\"\"Return (local_md_dir, image_dir, local_vis_dir).\"\"\"\n",
    "    local_md_dir = base / \"md\"\n",
    "    image_dir = base / \"images\" / name_without_ext\n",
    "    local_vis_dir = base / \"vis\"\n",
    "    for d in (local_md_dir, image_dir, local_vis_dir):\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "    return local_md_dir, image_dir, local_vis_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019cdc3b",
   "metadata": {},
   "source": [
    "## Core processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_pdf(pdf_path: Path, parse_method=PARSE_METHOD, out_root: Path = OUT_DIR) -> Dict[str, str]:\n",
    "    \"\"\"Run MinerU pipeline on a single PDF and save artifacts.\n",
    "\n",
    "    Returns a dict of output paths for reference.\n",
    "    \"\"\"\n",
    "    pdf_path = pdf_path.resolve()\n",
    "    name_without_ext = safe_name(pdf_path)\n",
    "    local_md_dir, image_dir, local_vis_dir = ensure_dirs(out_root, name_without_ext)\n",
    "\n",
    "    # Writers\n",
    "    md_writer = FileBasedDataWriter(local_md_dir.as_posix())\n",
    "    image_writer = FileBasedDataWriter(image_dir.as_posix())\n",
    "    vis_writer = FileBasedDataWriter(local_vis_dir.as_posix())\n",
    "    data_reader = FileBasedDataReader(pdf_path.as_posix())\n",
    "\n",
    "    # Dataset and inference\n",
    "    ds = PymuDocDataset(data_reader, parse_method)\n",
    "\n",
    "    # Run doc analysis; if you have a custom model path, pass it via kwargs as needed.\n",
    "    # Example: doc_analyze(ds, ocr=False, model_path=\"...\")\n",
    "    infer_result = ds.apply(doc_analyze, ocr=False)\n",
    "\n",
    "    # Choose pipeline mode; in many setups 'pipe_txt_mode' yields Markdown + images\n",
    "    pipe_result = infer_result.pipe_txt_mode(image_writer)\n",
    "\n",
    "    # Visualizations of layout and spans\n",
    "    vis_layout_pdf = (local_vis_dir / f\"{name_without_ext}_layout.pdf\").as_posix()\n",
    "    vis_spans_pdf = (local_vis_dir / f\"{name_without_ext}_spans.pdf\").as_posix()\n",
    "    pipe_result.draw_layout(vis_layout_pdf)\n",
    "    pipe_result.draw_span(vis_spans_pdf)\n",
    "\n",
    "    # Markdown + content list + middle json\n",
    "    md_file = f\"{name_without_ext}.md\"\n",
    "    content_list_file = f\"{name_without_ext}_content_list.json\"\n",
    "    middle_json_file = f\"{name_without_ext}_middle.json\"\n",
    "\n",
    "    pipe_result.dump_md(md_writer, md_file, image_dir.as_posix())\n",
    "    pipe_result.dump_content_list(md_writer, content_list_file, image_dir.as_posix())\n",
    "    pipe_result.dump_middle_json(md_writer, middle_json_file)\n",
    "\n",
    "    return {\n",
    "        \"md\": (local_md_dir / md_file).as_posix(),\n",
    "        \"content_list\": (local_md_dir / content_list_file).as_posix(),\n",
    "        \"middle_json\": (local_md_dir / middle_json_file).as_posix(),\n",
    "        \"vis_layout\": vis_layout_pdf,\n",
    "        \"vis_spans\": vis_spans_pdf,\n",
    "        \"images_dir\": image_dir.as_posix(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4052cdb",
   "metadata": {},
   "source": [
    "## Batch runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_batch(input_dir: Path = INPUT_DIR, max_pdfs: Optional[int] = MAX_PDFS) -> None:\n",
    "    parsed = load_parsed_list(PARSED_LIST_FILE)\n",
    "    count = 0\n",
    "    for pdf in tqdm(iter_pdfs(input_dir, recursive=RECURSIVE), desc=\"PDFs\"):\n",
    "        key = pdf.resolve().as_posix()\n",
    "        if key in parsed:\n",
    "            continue\n",
    "        try:\n",
    "            outs = process_pdf(pdf)\n",
    "            parsed.add(key)\n",
    "            print(f\"[OK] {pdf.name} -> {outs['md']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {pdf.name}: {e}\")\n",
    "        count += 1\n",
    "        if max_pdfs is not None and count >= max_pdfs:\n",
    "            break\n",
    "    save_parsed_list(PARSED_LIST_FILE, parsed)\n",
    "\n",
    "# Dry run check (won't process if no PDFs exist)\n",
    "print(\"Ready. Place PDFs under:\", INPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f653d8f",
   "metadata": {},
   "source": [
    "## Quick test on a single file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example:\n",
    "# sample_pdf = next(iter_pdfs(INPUT_DIR, recursive=RECURSIVE), None)\n",
    "# if sample_pdf is not None:\n",
    "#     process_pdf(sample_pdf)\n",
    "# else:\n",
    "#     print(\"No PDFs found for quick test.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
